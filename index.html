
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>LLM for Science @ NAACL 2024: Home</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this page -->
    <link href="css/main.css" rel="stylesheet">
    <link href="//fonts.googleapis.com/css?family=Roboto:400" rel="stylesheet">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">

</head>

<body>

<!-- <div class="blog-masthead">
    <div class="container">
        <nav class="navbar navbar-expand-md navbar-dark">
            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
                    data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
                    aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <a class="navbar-brand" href="/">USKB @ AKBC 2021</a>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav mr-auto">


                    <li class="nav-item active">

                        <a class="nav-link" href="/">Home</a>
                    </li>


                    <li class="nav-item">

                        <a class="nav-link" href="/abstracts.html">Featured Abstracts</a>
                    </li>


                    <li class="nav-item">

                        <a class="nav-link" href="/cfp.html">Call for Abstracts</a>
                    </li>


                    <li class="nav-item">

                        <a class="nav-link" href="/past">Past Workshops</a>
                    </li>

                </ul>
            </div>
        </nav>
    </div>
</div> -->

<div class="blog-header" style="background-image: url(static/images/jeju.jpeg); background-repeat: no-repeat; background-position: center; background-attachment: fixed; background-size: cover;">
        <div class="container text-center">
        <p></p>
        <h4 align="left" class="blog-title" style="color:white">LLM for Science @ NAACL 2024</h4>
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
                        <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
                        <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
            <p style="color: rgba(0, 0, 0, 0);">This text is semi-transparent.</p> 
    </div>
</div>
        <div class="container text-center">
        <p></p>
        <h1 class="blog-title"><font color="DarkRed">LLM for Science </font></h1>
        <p class="lead blog-description">
             Birds-Of-A-Feather (BoF) Session at <a href="https://www.akbc.ws/2022/">NAACL 2024, Mexico City, Mexico</a><br/>
            June 17, 2024<br/>
            <!--            Contact: <a href="mailto:uskb-workshop@googlegroups.com">uskb-workshop@googlegroups.com</a>-->
        </p>
    </div>

<div class="container">
    <div class="row">
        <div class="col-sm-12 blog-main">
            <h2 id="overview">Overview</h2>

            <p>The "LLM for Science" BoF session aims to assemble industry professionals, academic researchers, and AI enthusiasts who share a common interest in the use of Large Language Models (LLMs) in various scientific domains. Our primary goal is to delve into a deeper exploration of how LLMs are transforming traditional research methods in fields such as Chemistry, Physics, Biology, Material Science, and beyond. We aim to discuss how LLMs are employed for automatic data analysis, experiment design, and streamlining research processes. The session would also concentrate on key challenges and ethical considerations brought forth by the integration of AI in scientific research. Furthermore, we will seek to understand the potential of AI as autonomous scientists and how this could reshape the landscape of future scientific research. Particular areas of discourse will include the application of AI in Natural Science, Math, Finance, and Social Science; the rise of scientific document modeling and understanding; and exploring AI for academic services like automatic paper review, academic writing aid, and paper recommendations. 
</p>


            <p> <b>Contact:</b> LLM4Sci@gmail.com </p>

<!--             <h2 id="registration">Registration</h2>
            <p>Not needed.</p> <p><font color="Red">Attention!!!</font> Please use zoom <a href="https://temple.zoom.us/j/2508029698">https://temple.zoom.us/j/2508029698</a> for all workshop sessions. </p>
 -->
            <h2 id="important-dates">Schedule (GMT-6)</h2>
            <ul>
                <li>4:00 - 4:30 PM: Talk by Rui Zhang</li>
                <li>4:30 - 5:00 PM: Talk by Marti Hearst</li>
                <li>5:00 - 5:30 PM: Talk by Tianfan Fu</li>
            </ul>

            <h2 id="invited-speakers">Keynote Speakers</h2>

            <!-- <ul>
                <li><a href="https://cs.illinois.edu/about/people/faculty/hengji">Heng Ji</a>, UIUC</li>
                <li><a href="https://web.cs.ucla.edu/~yzsun/">Yizhou Sun</a>, UCLA</li>
                <li><a href="https://eagirre.github.io/">Eneko Agirre</a>, University of the Basque Country</li>
                <li><a href="https://www.microsoft.com/en-us/research/people/hoifung/">Hoifung Poon</a>, Microsoft Research</li>
            </ul> -->

            <!-- About Section -->
           <section  class="success" id="Speakers">
               <div class="container">
                   <!-- <div class="row">
                       <div class="col-lg-12 text-center">
                           <h2>Speakers</h2>
                           <hr class="star-light">
                       </div>
                   </div> -->
                   <div class="row">
                   <div class="col-lg-12">
                   <table style="border-spacing:30px; border-collapse: separate;" align="center">
                    <tr>
                    <td align="center">
                      <div>
                        <img src="static/images/hengji.png" style="width:140px;" align="middle">
                        <p><a href="https://cs.illinois.edu/about/people/faculty/hengji">Prof. Heng Ji</a> <br> UIUC <br> & Amazon Scholar <br> <b>Topic:</b> AI for Drug Discovery </p>
                      </div>
                    </td>
            
                     <td align="center">
                      <div>
                       <img src="static/images/zack.png" style="width:141px;" align="middle">
                       <p><a href="https://www.cis.upenn.edu/~zives/">Prof. Zachary Ives</a><br>Department Chair <br>University of Pennsylvania<br> <b>Topic:</b> AI for Database</p>
                       </div>
                    </td>
                     <td align="center">
                      <div>
                       <img src="static/images/marija.png" style="width:141px;" align="middle">
                       <p><a href="https://slavkovik.com/">Prof. Marija Slavkovik</a><br>Department Chair <br>University of Bergen<br> <b>Topic:</b> AI Ethics</p>
                       </div>
                    </td>
<!--                     <td align="center">
                     <div>
                      <img src="images/yizhou.png" style="width:141px;" align="middle">
                      <p><a href="https://web.cs.ucla.edu/~yzsun/">Prof. Yizhou Sun</a><br>University of California <br> Los Angeles</p>
                      </div>
                   </td> -->
                  </tr>

                </table>
               </div>
           </section>

<!-- <ul>
  <li>
            <p>Prof. Eneko Agirre: "<b>Few-shot Information Extraction:  Pre-train, prompt and entail</b>"</p>

<p><b>Abstract</b>: Deep Learning has made tremendous progress in Natural Language Processing (NLP), where large pre-trained language models (PLM) fine-tuned on the target task have become the predominant tool. More recently, in a process called prompting, NLP tasks are rephrased as natural language text, allowing us to better exploit linguistic knowledge learned by PLMs and resulting in significant improvements. Still, PLMs have limited inference ability. In the Textual Entailment task, systems need to output whether the truth of a certain textual hypothesis follows from the given premise text.  Manually annotated entailment datasets covering multiple inference phenomena have been used to infuse inference capabilities to PLMs. This talk will review these recent developments, and will present an approach that combines prompts and PLMs fine-tuned for textual entailment that yields state-of-the-art results on Information Extraction (IE) using only a small fraction of the annotations. The approach has additional benefits, like the ability to learn from different schemas and inference datasets. These developments enable a new paradigm for IE where the expert can define the domain-specific schema using natural language and directly run those specifications, annotating a handful of examples in the process. A user interface based on this new paradigm will also be presented. Beyond IE, inference capabilities could be extended, acquired and applied from other tasks, opening a new research avenue where entailment and downstream task performance improve in tandem.</p>

<p><b>Bio</b>: Eneko Agirre is a Professor of Informatics and Head of HiTZ Basque Center of Language Technnology at
  the University of the Basque Country, UPV/EHU, in San Sebastian, Spain. He has been active in Natural Language
  Processing and Computational Linguistics for decades. He received the Spanish Informatics Research Award in 2021,
  and is one of the 74 fellows of the Association of Computational Linguistics (ACL). He was President of ACL's
  SIGLEX, member of the editorial board of Computational Linguistics, Journal of Artificial Intelligence Research
  and Action editor for the Transactions of the ACL. He is co-founder of the Joint Conference on Lexical and
  Computational Semantics (*SEM). Recipient of three Google Research Awards and five best paper awards and nominations. Dissertations under his supervision received best PhD awards by EurAI, the Spanish NLP society and the Spanish Informatics Scientific Association. He has over 200 publications across a wide range of NLP and AI topics. His research spans topics such as Word Sense Disambiguation, Semantic Textual Similarity, Unsupervised Machine Translation and resources for Basque. Most recently his research focuses on inference and deep learning language models.</p>
  </li>

  <li>
            <p>Prof. Heng Ji: "<b>Few-shot Event Argument Extraction via Natural Language or Programming Language Generation</b>"</p>

<p><b>Abstract</b>: The goal of the event argument role labeling task is to find finding the arguments
  (participants) of an event. Traditional methods model this task as a supervised classification problem
  that requires a large amount of training data (around 4,000 fully annotated sentences). By contrast,
  when humans know some events happened (e.g., Halloween parade in Champaign), they would expect to know a
  list of arguments - attendees, time, location, organizer, etc., actively seek information to fill in these
  slots by reading news or social media, and then they will be able to describe the information about these
  arguments to their friends. Therefore, if an intelligent information system knows how to narrate an event,
  it should be able to fill in the slots for the expected argument roles. We propose to re-frame the problem
  as conditional generation given a template (a list of arguments for each event type). Conditioned on the
  unfilled template and a given natural language context, the model is asked to generate a filled-in template
  with arguments. We can train this generator using a large language model learned from natural language, or,
  even better, from programming language, both of which are readily available. For example, event-argument
  structures can be represented as a class object using code. This alignment between structures and code
  enables us to take advantage of Programming Language features such as inheritance and type annotation to
  introduce external knowledge or add constraints. Our model does not require any substantial amount of
  annotations for the information extraction task, and thus it's highly effective for zero-shot or
  few-shot settings. Also it can work with long contexts beyond single sentences, and bring us one step
  closer to the original goal of information extraction - constructing a knowledge base from the entire corpus.
  When only using 50 training instances for each event type, our framework is comparable to fully-supervised
  models trained on 4,202 event instances. When given the same 50-shot data, our approach outperforms current
  state-of-the-art (SOTA) by 20.8% absolute F1.</p>

<p><b>Bio</b>: Heng Ji is a professor at Computer Science Department, and an affiliated faculty member at
  Electrical and Computer Engineering Department of University of Illinois at Urbana-Champaign. She is also an
  Amazon Scholar. She received her B.A. and M. A. in Computational Linguistics from Tsinghua University,
  and her M.S. and Ph.D. in Computer Science from New York University. Her research interests focus on
  Natural Language Processing, especially on Multimedia Multilingual Information Extraction, Knowledge
  Base Population and Knowledge-driven Generation. She was selected as "Young Scientist" and a member of
  the Global Future Council on the Future of Computing by the World Economic Forum in 2016 and 2017.
  She was named as part of Women Leaders of Conversational AI (Class of 2023) by Project Voice. The awards
  she received include "AI's 10 to Watch" Award by IEEE Intelligent Systems in 2013, NSF CAREER award in 2009,
  PACLIC2012 Best paper runner-up, "Best of ICDM2013" paper award, "Best of SDM2013" paper award, ACL2018
  Best Demo paper nomination, ACL2020 Best Demo Paper Award, NAACL2021 Best Demo Paper Award, Google Research
  Award in 2009 and 2014, IBM Watson Faculty Award in 2012 and 2014 and Bosch Research Award in 2014-2018.
  She was invited by the Secretary of the U.S. Air Force and AFRL to join Air Force Data Analytics Expert
  Panel to inform the Air Force Strategy 2030. She is the lead of many multi-institution projects and tasks,
  including the U.S. ARL projects on information fusion and knowledge networks construction, DARPA DEFT
  Tinker Bell team and DARPA KAIROS RESIN team. She has coordinated the NIST TAC Knowledge Base Population
  task since 2010. She was the associate editor for IEEE/ACM Transaction on Audio, Speech, and Language
  Processing, and served as the Program Committee Co-Chair of many conferences including NAACL-HLT2018
  and AACL-IJCNLP2022. She is elected as the North American Chapter of the Association for Computational
  Linguistics (NAACL) secretary 2020-2023. Her research has been widely supported by the U.S. government
  agencies (DARPA, ARL, IARPA, NSF, AFRL, DHS) and industry (Amazon, Google, Facebook, Bosch, IBM, Disney). </p>
  </li>

  <li>
            <p>Dr. Hoifung Poon: "<b>Self-Supervised AI for Precision Health</b>"</p>

<p><b>Abstract</b>: The advent of big data promises to revolutionize medicine by making it more personalized and effective, but big data also presents a grand challenge of information overload. For example, tumor sequencing has become routine in cancer treatment, yet interpreting the genomic data requires painstakingly curating knowledge from a vast biomedical literature, which grows by thousands of papers every day. Electronic medical records contain high-definition patient information for speeding up clinical trial recruitment and drug development, but curating such real-world evidence from clinical notes can take hours for a single patient. Natural language processing (NLP) can play a key role in interpreting big data for precision medicine. In particular, machine reading can help unlock knowledge from text by substantially improving curation efficiency. However, standard supervised methods require labeled examples, which are expensive and time-consuming to produce at scale. In this talk, I'll present Project Hanover, where we overcome the annotation bottleneck by combining deep learning with probabilistic logic, by exploiting self-supervision from readily available resources such as ontologies and databases, and by leveraging domain-specific pretraining on unlabeled text. This enables us to extract knowledge from tens of millions of publications, structure real-world data for millions of cancer patients, and apply the extracted knowledge and real-world evidence to supporting precision oncology. </p>

<p><b>Bio</b>: Hoifung Poon is the Senior Director of Biomedical NLP at Microsoft Research and an affiliated professor at the University of Washington Medical School. He leads Project Hanover, with the overarching goal of structuring medical data for precision medicine. He has given tutorials on this topic at top conferences such as the Association for Computational Linguistics (ACL) and the Association for the Advancement of Artificial Intelligence (AAAI). His research spans a wide range of problems in machine learning and natural language processing (NLP), and his prior work has been recognized with Best Paper Awards from premier venues such as the North American Chapter of the Association for Computational Linguistics (NAACL), Empirical Methods in Natural Language Processing (EMNLP), and Uncertainty in AI (UAI). He received his PhD in Computer Science and Engineering from University of Washington, specializing in machine learning and NLP. </p>
  </li>

  <li>
            <p>Prof. Yizhou Sun: "<b>Combining Representation Learning and Logical Rule Reasoning for Knowledge Graph Inference</b>"</p>

<p><b>Abstract</b>: Knowledge graph inference has been studied extensively due to its wide applications. It has been addressed by two lines of research, i.e., the more traditional logical rule reasoning and the more recent knowledge graph embedding (KGE). In this talk, we will introduce two recent developments in our group to combine these two worlds. First, we propose to leverage logical rules to bring in high-order dependency among entities and relations for KGE. By limiting the logical rules to be the definite Horn clauses, we are able to fully exploit the knowledge in logical rules and enable the mutual enhancement of logical rule-based reasoning and KGE in an extremely efficient way. Second, we propose to handle logical queries by representing fuzzy sets as specially designed vectors and retrieving answers via dense vector computation. In particular, we provide embedding-based logical operators that strictly follow the axioms required in fuzzy logic, which can be trained by self-supervised knowledge completion tasks. With additional query-answer pairs, the performance can be further enhanced. With these evidence, we believe combining logic with representation learning provides a promising direction for knowledge reasoning. </p>

<p><b>Bio</b>: Yizhou Sun is an associate professor at department of computer science of UCLA. She received her Ph.D. in Computer Science from the University of Illinois at Urbana-Champaign in 2012. Her principal research interest is on mining graphs/networks, and more generally in data mining, machine learning, and network science, with a focus on modeling novel problems and proposing scalable algorithms for large-scale, real-world applications. She is a pioneer researcher in mining heterogeneous information network, with a recent focus on deep learning on graphs/networks. Yizhou has over 150 publications in books, journals, and major conferences. Tutorials of her research have been given in many premier conferences. She is a recipient of KDD Best Student Paper Award, ACM SIGKDD Doctoral Dissertation Award, Yahoo ACE (Academic Career Enhancement) Award, NSF CAREER Award, CS@ILLINOIS Distinguished Educator Award, Amazon Research Awards (twice), Okawa Foundation Research Award, and VLDB Test of Time Award. </p>
  </li>
  </ul> -->


<!--                        
            <h2 id="schedule">Schedule</h2>
            <p><font color="Red">Attention!!!</font> Please use zoom <a href="https://temple.zoom.us/j/2508029698">https://temple.zoom.us/j/2508029698</a> for all workshop sessions. </p>
            <table style="width: 100%">
              <colgroup>
   <col span="1" style="width: 50%;">
   <col span="1" style="width: 22%;">
   <col span="1" style="width: 16%;">
   <col span="1" style="width: 12%;">
</colgroup>
<tbody>
  <tr>
    <th>Session</th>
    <th>London time</th>
    <th>Speaker's local time</th>
    <th>Session chair</th>
  </tr>
  <tr style="background-color:lightgreen;">
    <td>Opening speech</td>
    <td>14:00-14:05 pm (5 mins)</td>
    <td>15:00-15:05 pm</td>
    <td>Barbara Plank</td>
  </tr>
  <tr>
    <td>
      <p>Keynote by Prof. Eneko Agirre</p><p>"Few-shot Information Extraction:  Pre-train, prompt and entail"</p></td>
    <td>14:05-14:45 pm (40mins)</td>
    <td>15:05-15:45 pm</td>
    <td>Barbara Plank</td>
  </tr>
  <tr style="background-color:lightgreen;">
    <td><p>Keynote by Prof. Heng Ji</p><p>"Few-shot Event Argument Extraction via Natural Language or Programming Language Generation"</p></td>
    <td>14:50-15:30 pm (40mins)</td>
    <td>09:50-10:30 am</td>
    <td>Wenpeng Yin</td>
  </tr>
  <tr>
    <td>Coffee break</td>
    <td>15:30-16:00 pm (30mins)</td>
    <td></td>
    <td></td>
  </tr>
  <tr style="background-color:lightgreen;">
    <td><p>Keynote by Dr. Hoifung Poon</p><p>"Self-Supervised AI for Precision Health"</p></td>
    <td>16:00-16:40 pm (40 mins)</td>
    <td>09:00-09:40 am</td>
    <td>Benjamin Roth</td>
  </tr>
  <tr>
    <td><p>Keynote by Prof. Yizhou Sun</p><p>"Combining Representation Learning and Logical Rule Reasoning for Knowledge Graph Inference"</p></td>
    <td>16:40-17:20 pm (40 mins)</td>
    <td>09:40-10:20 am</td>
    <td>Muhao Chen</td>
  </tr>
  <tr style="background-color:lightgreen;">
    <td>Accepted paper "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction". Presenter: Ningyu Zhang</td>
    <td>17:20-17:28 pm (8 mins)</td>
    <td> 01:20-01:28 am (11/6/2022)</td>
    <td> Hongming Zhang</td>
  </tr>
  <tr>
    <td>Accepted paper "SepLL: Separating Latent Class Labels from Weak Supervision Noise". Presenter: Andreas Stephan</td>
    <td>17:28-17:36 pm (8 mins)</td>
    <td> 18:28-18:36 pm</td>
    <td> Hongming Zhang</td>
  </tr>
  <tr style="background-color:lightgreen;">
    <td>Accepted paper "OpenStance: Real-world Zero-shot Stance Detection". Presenter: Hanzi Xu</td>
    <td>17:36-17:44 pm (8 mins)</td>
    <td> 13:36-13:44 pm</td>
    <td> Hongming Zhang</td>
  </tr>
  <tr>
    <td>Accepted paper "Cross-Lingual Speaker Identification Using Distant Supervision". Presenter: Ben Zhou</td>
    <td>17:44-17:52 pm (8 mins)</td>
    <td>13:44-13:52 pm </td>
    <td> Hongming Zhang</td>
  </tr>
  <tr style="background-color:lightgreen;">
    <td>Accepted paper "Towards Improved Distantly Supervised Multilingual Named-Entity Recognition for Tweets". Presenter: Ramy Eskander</td>
    <td>17:52-18:00 pm (8 mins)</td>
    <td> 13:52-14:00 pm</td>
    <td> Hongming Zhang</td>
  </tr>
  <tr>
    <td>Closing Remarks</td>
    <td>18:00-18:05 pm (5 mins)</td>
    <td>14:00-14:05 pm </td>
    <td>Wenpeng Yin </td>
  </tr>
</tbody>
</table>
 -->
            <h2 id="organizing-committee">Organizing Committee</h2>

            <section  class="success" id="Organizers">
                <div class="container">
                    <div class="row">
                    <div class="col-lg-12">
                    <table style="border-spacing:30px; border-collapse: separate;" align="center">
                     <tr>
                     <td align="center">
                       <div>
                         <img src="static/images/wenpeng.png" style="width:120px;" align="middle">
                         <p><a href="https://www.wenpengyin.org/">Wenpeng Yin</a> <br>Asst. Prof. <br> Penn State <br>University</p>
                       </div>
          






                   </tr>

                 </table>
                </div>
            </section>
            <h2 id="organizing-committee">Advisory Boards</h2>

            <section  class="success" id="Organizers">
                <div class="container">
                    <div class="row">
                    <div class="col-lg-12">
                    <table style="border-spacing:30px; border-collapse: separate;" align="center">
                     <tr>


                    <td align="center">
                     <div>
                      <img src="https://res.cloudinary.com/ysm/image/upload/yms/prod/c2965e7f-1ca8-4412-b553-3d464d23e7f6" style="width:120px;" align="middle">
                      <p><a href="https://najoung.kim/">Mark Gerstein</a><br>Prof. <br>Yale University</p>
                      </div>
                   </td>
                  <td align="center">
                   <div>
                    <img src="static/images/arman.png" style="width:120px;" align="middle">
                    <p><a href="https://cocoxu.github.io/">Arman Cohan</a><br>Asst. Prof. <br>Yale University</p>
                    </div>
                 </td>  
                    

                   </tr>

                 </table>
                </div>
            </section>
            <!-- <ul>
                <li><a href="https://www.wenpengyin.org/">Wenpeng Yin</a>, Temple University</li>
                <li><a href="https://muhaochen.github.io/">Muhao Chen</a>, University of Southern California</li>
                <li><a href="https://wilburone.github.io/">Lifu Huang</a>, Virginia Tech</li>
                <li><a href="http://web.cse.ohio-state.edu/~sun.397/">Huan Sun</a>, The Ohio State University</li>
                <li><a href="https://panda0881.github.io/Hongming_Homepage/">Hongming Zhang</a>, Tencent AI Lab, Seattle</li>
                <li><a href="https://www.benjaminroth.net/">Benjamin Roth</a>, University of Vienna</li>
                <li><a href="https://bplank.github.io/">Barbara Plank</a>, LMU Munich</li>
            </ul> -->


        </div><!-- /.blog-main -->

    </div><!-- /.row -->

</div><!-- /.container -->

<!--<footer class="blog-footer">-->
<!--    <p>-->
<!--        <a href="https://github.com/uskb-workshop/uskb-workshop.github.io" class="footer-icon">-->
<!--            <img height="24" width="24" src="https://unpkg.com/simple-icons@latest/icons/github.svg"/>-->
<!--        </a>-->
<!--        <a href="https://getbootstrap.com" class="footer-icon">-->
<!--            <img height="24" width="24" src="https://unpkg.com/simple-icons@latest/icons/bootstrap.svg"/>-->
<!--        </a>-->
<!--    </p>-->
<!--</footer>-->


<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>
</body>
</html>
